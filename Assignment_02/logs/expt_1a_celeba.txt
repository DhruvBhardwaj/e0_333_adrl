cuda:1
-----------------------------------------------------------
-----------------------------------------------------------
ENCODER
-----------------------------------------------------------
ModuleList(
  (0): convBlock(
    (net): ModuleList(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.2, inplace=False)
      (2): GroupNorm(4, 64, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.2, inplace=False)
      (6): GroupNorm(4, 64, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
  (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (2): convBlock(
    (net): ModuleList(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.2, inplace=False)
      (2): GroupNorm(4, 128, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.2, inplace=False)
      (6): GroupNorm(4, 128, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
  (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (4): convBlock(
    (net): ModuleList(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.2, inplace=False)
      (2): GroupNorm(4, 256, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.2, inplace=False)
      (6): GroupNorm(4, 256, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
)
-----------------------------------------------------------
-----------------------------------------------------------
DECODER
-----------------------------------------------------------
ModuleList(
  (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
  (1): convBlock(
    (net): ModuleList(
      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.2, inplace=False)
      (2): GroupNorm(4, 128, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.2, inplace=False)
      (6): GroupNorm(4, 128, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
  (2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
  (3): convBlock(
    (net): ModuleList(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.2, inplace=False)
      (2): GroupNorm(4, 64, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.2, inplace=False)
      (6): GroupNorm(4, 64, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
)
-----------------------------------------------------------
ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(3, 3), padding=(4, 4))
-----------------------------------------------------------
Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))
-----------------------------------------------------------
Tanh()
-----------------------------------------------------------
[INFO] DATA_PATH=/home/dhruvb/adrl/datasets/img_align_celeba_resampled/, BATCH_SIZE=64
[INFO] Found data set with 202599 samples
-----------------------------------------------------------
Starting Training of model
Epoch 1......Step: 500/3166....... Loss=  6.1456e+06 (l[xt<-xt1]=  6.1456e+06,l[x0<-x1]=         0.0)
Epoch 1......Step: 1000/3166....... Loss=   1.229e+07 (l[xt<-xt1]=   1.229e+07,l[x0<-x1]=         0.0)
Epoch 1......Step: 1500/3166....... Loss=  1.8433e+07 (l[xt<-xt1]=  1.8433e+07,l[x0<-x1]=         0.0)
Epoch 1......Step: 2000/3166....... Loss=  2.4578e+07 (l[xt<-xt1]=  2.4578e+07,l[x0<-x1]=         0.0)
Epoch 1......Step: 2500/3166....... Loss=  3.0722e+07 (l[xt<-xt1]=  3.0722e+07,l[x0<-x1]=         0.0)
Epoch 1......Step: 3000/3166....... Loss=  3.6866e+07 (l[xt<-xt1]=  3.6866e+07,l[x0<-x1]=         0.0)
202599
Epoch 1/500 Done, Loss =   1.2289e+04 (l[xt<-xt1]=  1.2289e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=15798        seconds
-----------------------------------------------------------
Epoch 2......Step: 500/3166....... Loss=  6.1426e+06 (l[xt<-xt1]=  6.1426e+06,l[x0<-x1]=         0.0)
Epoch 2......Step: 1000/3166....... Loss=  1.2279e+07 (l[xt<-xt1]=  1.2279e+07,l[x0<-x1]=         0.0)
Epoch 2......Step: 1500/3166....... Loss=  1.8405e+07 (l[xt<-xt1]=  1.8405e+07,l[x0<-x1]=         0.0)
Epoch 2......Step: 2000/3166....... Loss=  2.4514e+07 (l[xt<-xt1]=  2.4514e+07,l[x0<-x1]=         0.0)
Epoch 2......Step: 2500/3166....... Loss=  3.0605e+07 (l[xt<-xt1]=  3.0605e+07,l[x0<-x1]=         0.0)
Epoch 2......Step: 3000/3166....... Loss=  3.6681e+07 (l[xt<-xt1]=  3.6681e+07,l[x0<-x1]=         0.0)
202599
Epoch 2/500 Done, Loss =   1.2222e+04 (l[xt<-xt1]=  1.2222e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16967        seconds
-----------------------------------------------------------
Epoch 3......Step: 500/3166....... Loss=  6.0615e+06 (l[xt<-xt1]=  6.0615e+06,l[x0<-x1]=         0.0)
Epoch 3......Step: 1000/3166....... Loss=  1.2115e+07 (l[xt<-xt1]=  1.2115e+07,l[x0<-x1]=         0.0)
Epoch 3......Step: 1500/3166....... Loss=  1.8161e+07 (l[xt<-xt1]=  1.8161e+07,l[x0<-x1]=         0.0)
Epoch 3......Step: 2000/3166....... Loss=  2.4201e+07 (l[xt<-xt1]=  2.4201e+07,l[x0<-x1]=         0.0)
Epoch 3......Step: 2500/3166....... Loss=  3.0235e+07 (l[xt<-xt1]=  3.0235e+07,l[x0<-x1]=         0.0)
Epoch 3......Step: 3000/3166....... Loss=  3.6265e+07 (l[xt<-xt1]=  3.6265e+07,l[x0<-x1]=         0.0)
202599
Epoch 3/500 Done, Loss =   1.2086e+04 (l[xt<-xt1]=  1.2086e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=17523        seconds
-----------------------------------------------------------
Epoch 4......Step: 500/3166....... Loss=  6.0231e+06 (l[xt<-xt1]=  6.0231e+06,l[x0<-x1]=         0.0)
Epoch 4......Step: 1000/3166....... Loss=  1.2041e+07 (l[xt<-xt1]=  1.2041e+07,l[x0<-x1]=         0.0)
Epoch 4......Step: 1500/3166....... Loss=  1.8055e+07 (l[xt<-xt1]=  1.8055e+07,l[x0<-x1]=         0.0)
Epoch 4......Step: 2000/3166....... Loss=  2.4065e+07 (l[xt<-xt1]=  2.4065e+07,l[x0<-x1]=         0.0)
Epoch 4......Step: 2500/3166....... Loss=  3.0071e+07 (l[xt<-xt1]=  3.0071e+07,l[x0<-x1]=         0.0)
Epoch 4......Step: 3000/3166....... Loss=  3.6074e+07 (l[xt<-xt1]=  3.6074e+07,l[x0<-x1]=         0.0)
202599
Epoch 4/500 Done, Loss =   1.2023e+04 (l[xt<-xt1]=  1.2023e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16525        seconds
-----------------------------------------------------------
Epoch 5......Step: 500/3166....... Loss=  5.9977e+06 (l[xt<-xt1]=  5.9977e+06,l[x0<-x1]=         0.0)
Epoch 5......Step: 1000/3166....... Loss=  1.1993e+07 (l[xt<-xt1]=  1.1993e+07,l[x0<-x1]=         0.0)
Epoch 5......Step: 1500/3166....... Loss=  1.7985e+07 (l[xt<-xt1]=  1.7985e+07,l[x0<-x1]=         0.0)
Epoch 5......Step: 2000/3166....... Loss=  2.3973e+07 (l[xt<-xt1]=  2.3973e+07,l[x0<-x1]=         0.0)
Epoch 5......Step: 2500/3166....... Loss=  2.9959e+07 (l[xt<-xt1]=  2.9959e+07,l[x0<-x1]=         0.0)
Epoch 5......Step: 3000/3166....... Loss=  3.5942e+07 (l[xt<-xt1]=  3.5942e+07,l[x0<-x1]=         0.0)
202599
Epoch 5/500 Done, Loss =    1.198e+04 (l[xt<-xt1]=   1.198e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16432        seconds
-----------------------------------------------------------
Epoch 6......Step: 500/3166....... Loss=  5.9798e+06 (l[xt<-xt1]=  5.9798e+06,l[x0<-x1]=         0.0)
Epoch 6......Step: 1000/3166....... Loss=  1.1957e+07 (l[xt<-xt1]=  1.1957e+07,l[x0<-x1]=         0.0)
Epoch 6......Step: 1500/3166....... Loss=  1.7932e+07 (l[xt<-xt1]=  1.7932e+07,l[x0<-x1]=         0.0)
Epoch 6......Step: 2000/3166....... Loss=  2.3904e+07 (l[xt<-xt1]=  2.3904e+07,l[x0<-x1]=         0.0)
Epoch 6......Step: 2500/3166....... Loss=  2.9874e+07 (l[xt<-xt1]=  2.9874e+07,l[x0<-x1]=         0.0)
Epoch 6......Step: 3000/3166....... Loss=  3.5841e+07 (l[xt<-xt1]=  3.5841e+07,l[x0<-x1]=         0.0)
202599
Epoch 6/500 Done, Loss =   1.1946e+04 (l[xt<-xt1]=  1.1946e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16271        seconds
-----------------------------------------------------------
Epoch 7......Step: 500/3166....... Loss=  5.9647e+06 (l[xt<-xt1]=  5.9647e+06,l[x0<-x1]=         0.0)
Epoch 7......Step: 1000/3166....... Loss=  1.1927e+07 (l[xt<-xt1]=  1.1927e+07,l[x0<-x1]=         0.0)
Epoch 7......Step: 1500/3166....... Loss=  1.7889e+07 (l[xt<-xt1]=  1.7889e+07,l[x0<-x1]=         0.0)
Epoch 7......Step: 2000/3166....... Loss=  2.3848e+07 (l[xt<-xt1]=  2.3848e+07,l[x0<-x1]=         0.0)
Epoch 7......Step: 2500/3166....... Loss=  2.9806e+07 (l[xt<-xt1]=  2.9806e+07,l[x0<-x1]=         0.0)
Epoch 7......Step: 3000/3166....... Loss=  3.5761e+07 (l[xt<-xt1]=  3.5761e+07,l[x0<-x1]=         0.0)
202599
Epoch 7/500 Done, Loss =    1.192e+04 (l[xt<-xt1]=   1.192e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16319        seconds
-----------------------------------------------------------
Epoch 8......Step: 500/3166....... Loss=  5.9523e+06 (l[xt<-xt1]=  5.9523e+06,l[x0<-x1]=         0.0)
Epoch 8......Step: 1000/3166....... Loss=  1.1904e+07 (l[xt<-xt1]=  1.1904e+07,l[x0<-x1]=         0.0)
Epoch 8......Step: 1500/3166....... Loss=  1.7854e+07 (l[xt<-xt1]=  1.7854e+07,l[x0<-x1]=         0.0)
Epoch 8......Step: 2000/3166....... Loss=  2.3803e+07 (l[xt<-xt1]=  2.3803e+07,l[x0<-x1]=         0.0)
Epoch 8......Step: 2500/3166....... Loss=  2.9749e+07 (l[xt<-xt1]=  2.9749e+07,l[x0<-x1]=         0.0)
Epoch 8......Step: 3000/3166....... Loss=  3.5694e+07 (l[xt<-xt1]=  3.5694e+07,l[x0<-x1]=         0.0)
202599
Epoch 8/500 Done, Loss =   1.1897e+04 (l[xt<-xt1]=  1.1897e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16215        seconds
-----------------------------------------------------------
Epoch 9......Step: 500/3166....... Loss=  5.9428e+06 (l[xt<-xt1]=  5.9428e+06,l[x0<-x1]=         0.0)
Epoch 9......Step: 1000/3166....... Loss=  1.1883e+07 (l[xt<-xt1]=  1.1883e+07,l[x0<-x1]=         0.0)
Epoch 9......Step: 1500/3166....... Loss=  1.7823e+07 (l[xt<-xt1]=  1.7823e+07,l[x0<-x1]=         0.0)
Epoch 9......Step: 2000/3166....... Loss=  2.3762e+07 (l[xt<-xt1]=  2.3762e+07,l[x0<-x1]=         0.0)
Epoch 9......Step: 2500/3166....... Loss=  2.9699e+07 (l[xt<-xt1]=  2.9699e+07,l[x0<-x1]=         0.0)
Epoch 9......Step: 3000/3166....... Loss=  3.5635e+07 (l[xt<-xt1]=  3.5635e+07,l[x0<-x1]=         0.0)
202599
Epoch 9/500 Done, Loss =   1.1878e+04 (l[xt<-xt1]=  1.1878e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16092        seconds
-----------------------------------------------------------
Epoch 10......Step: 500/3166....... Loss=  5.9336e+06 (l[xt<-xt1]=  5.9336e+06,l[x0<-x1]=         0.0)
Epoch 10......Step: 1000/3166....... Loss=  1.1866e+07 (l[xt<-xt1]=  1.1866e+07,l[x0<-x1]=         0.0)
Epoch 10......Step: 1500/3166....... Loss=  1.7798e+07 (l[xt<-xt1]=  1.7798e+07,l[x0<-x1]=         0.0)
Epoch 10......Step: 2000/3166....... Loss=  2.3728e+07 (l[xt<-xt1]=  2.3728e+07,l[x0<-x1]=         0.0)
Epoch 10......Step: 2500/3166....... Loss=  2.9656e+07 (l[xt<-xt1]=  2.9656e+07,l[x0<-x1]=         0.0)
Epoch 10......Step: 3000/3166....... Loss=  3.5585e+07 (l[xt<-xt1]=  3.5585e+07,l[x0<-x1]=         0.0)
202599
Epoch 10/500 Done, Loss =   1.1861e+04 (l[xt<-xt1]=  1.1861e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=17084        seconds
-----------------------------------------------------------
Epoch 11......Step: 500/3166....... Loss=  5.9256e+06 (l[xt<-xt1]=  5.9256e+06,l[x0<-x1]=         0.0)
Epoch 11......Step: 1000/3166....... Loss=  1.1851e+07 (l[xt<-xt1]=  1.1851e+07,l[x0<-x1]=         0.0)
Epoch 11......Step: 1500/3166....... Loss=  1.7774e+07 (l[xt<-xt1]=  1.7774e+07,l[x0<-x1]=         0.0)
Epoch 11......Step: 2000/3166....... Loss=  2.3698e+07 (l[xt<-xt1]=  2.3698e+07,l[x0<-x1]=         0.0)
Epoch 11......Step: 2500/3166....... Loss=   2.962e+07 (l[xt<-xt1]=   2.962e+07,l[x0<-x1]=         0.0)
Epoch 11......Step: 3000/3166....... Loss=  3.5541e+07 (l[xt<-xt1]=  3.5541e+07,l[x0<-x1]=         0.0)
202599
Epoch 11/500 Done, Loss =   1.1847e+04 (l[xt<-xt1]=  1.1847e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=17515        seconds
-----------------------------------------------------------
Epoch 12......Step: 500/3166....... Loss=  5.9193e+06 (l[xt<-xt1]=  5.9193e+06,l[x0<-x1]=         0.0)
Epoch 12......Step: 1000/3166....... Loss=  1.1838e+07 (l[xt<-xt1]=  1.1838e+07,l[x0<-x1]=         0.0)
Epoch 12......Step: 1500/3166....... Loss=  1.7756e+07 (l[xt<-xt1]=  1.7756e+07,l[x0<-x1]=         0.0)
Epoch 12......Step: 2000/3166....... Loss=  2.3673e+07 (l[xt<-xt1]=  2.3673e+07,l[x0<-x1]=         0.0)
Epoch 12......Step: 2500/3166....... Loss=  2.9588e+07 (l[xt<-xt1]=  2.9588e+07,l[x0<-x1]=         0.0)
Epoch 12......Step: 3000/3166....... Loss=  3.5502e+07 (l[xt<-xt1]=  3.5502e+07,l[x0<-x1]=         0.0)
202599
Epoch 12/500 Done, Loss =   1.1834e+04 (l[xt<-xt1]=  1.1834e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=17415        seconds
-----------------------------------------------------------
Epoch 13......Step: 500/3166....... Loss=  5.9136e+06 (l[xt<-xt1]=  5.9136e+06,l[x0<-x1]=         0.0)
Epoch 13......Step: 1000/3166....... Loss=  1.1826e+07 (l[xt<-xt1]=  1.1826e+07,l[x0<-x1]=         0.0)
Epoch 13......Step: 1500/3166....... Loss=  1.7739e+07 (l[xt<-xt1]=  1.7739e+07,l[x0<-x1]=         0.0)
Epoch 13......Step: 2000/3166....... Loss=  2.3651e+07 (l[xt<-xt1]=  2.3651e+07,l[x0<-x1]=         0.0)
Epoch 13......Step: 2500/3166....... Loss=  2.9562e+07 (l[xt<-xt1]=  2.9562e+07,l[x0<-x1]=         0.0)
Epoch 13......Step: 3000/3166....... Loss=  3.5471e+07 (l[xt<-xt1]=  3.5471e+07,l[x0<-x1]=         0.0)
202599
Epoch 13/500 Done, Loss =   1.1824e+04 (l[xt<-xt1]=  1.1824e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16995        seconds
-----------------------------------------------------------
Epoch 14......Step: 500/3166....... Loss=  5.9087e+06 (l[xt<-xt1]=  5.9087e+06,l[x0<-x1]=         0.0)
Epoch 14......Step: 1000/3166....... Loss=  1.1817e+07 (l[xt<-xt1]=  1.1817e+07,l[x0<-x1]=         0.0)
Epoch 14......Step: 1500/3166....... Loss=  1.7724e+07 (l[xt<-xt1]=  1.7724e+07,l[x0<-x1]=         0.0)
Epoch 14......Step: 2000/3166....... Loss=  2.3631e+07 (l[xt<-xt1]=  2.3631e+07,l[x0<-x1]=         0.0)
Epoch 14......Step: 2500/3166....... Loss=  2.9537e+07 (l[xt<-xt1]=  2.9537e+07,l[x0<-x1]=         0.0)
Epoch 14......Step: 3000/3166....... Loss=  3.5443e+07 (l[xt<-xt1]=  3.5443e+07,l[x0<-x1]=         0.0)
202599
Epoch 14/500 Done, Loss =   1.1814e+04 (l[xt<-xt1]=  1.1814e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=17254        seconds
-----------------------------------------------------------
Epoch 15......Step: 500/3166....... Loss=  5.9045e+06 (l[xt<-xt1]=  5.9045e+06,l[x0<-x1]=         0.0)
Epoch 15......Step: 1000/3166....... Loss=  1.1809e+07 (l[xt<-xt1]=  1.1809e+07,l[x0<-x1]=         0.0)
Epoch 15......Step: 1500/3166....... Loss=  1.7713e+07 (l[xt<-xt1]=  1.7713e+07,l[x0<-x1]=         0.0)
Epoch 15......Step: 2000/3166....... Loss=  2.3617e+07 (l[xt<-xt1]=  2.3617e+07,l[x0<-x1]=         0.0)
Epoch 15......Step: 2500/3166....... Loss=   2.952e+07 (l[xt<-xt1]=   2.952e+07,l[x0<-x1]=         0.0)
Epoch 15......Step: 3000/3166....... Loss=  3.5423e+07 (l[xt<-xt1]=  3.5423e+07,l[x0<-x1]=         0.0)
202599
Epoch 15/500 Done, Loss =   1.1807e+04 (l[xt<-xt1]=  1.1807e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=17524        seconds
-----------------------------------------------------------
Epoch 16......Step: 500/3166....... Loss=  5.9012e+06 (l[xt<-xt1]=  5.9012e+06,l[x0<-x1]=         0.0)
Epoch 16......Step: 1000/3166....... Loss=  1.1803e+07 (l[xt<-xt1]=  1.1803e+07,l[x0<-x1]=         0.0)
Epoch 16......Step: 1500/3166....... Loss=  1.7703e+07 (l[xt<-xt1]=  1.7703e+07,l[x0<-x1]=         0.0)
Epoch 16......Step: 2000/3166....... Loss=  2.3604e+07 (l[xt<-xt1]=  2.3604e+07,l[x0<-x1]=         0.0)
Epoch 16......Step: 2500/3166....... Loss=  2.9504e+07 (l[xt<-xt1]=  2.9504e+07,l[x0<-x1]=         0.0)
Epoch 16......Step: 3000/3166....... Loss=  3.5404e+07 (l[xt<-xt1]=  3.5404e+07,l[x0<-x1]=         0.0)
202599
Epoch 16/500 Done, Loss =   1.1801e+04 (l[xt<-xt1]=  1.1801e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=17391        seconds
-----------------------------------------------------------
Epoch 17......Step: 500/3166....... Loss=  5.8986e+06 (l[xt<-xt1]=  5.8986e+06,l[x0<-x1]=         0.0)
Epoch 17......Step: 1000/3166....... Loss=  1.1797e+07 (l[xt<-xt1]=  1.1797e+07,l[x0<-x1]=         0.0)
Epoch 17......Step: 1500/3166....... Loss=  1.7696e+07 (l[xt<-xt1]=  1.7696e+07,l[x0<-x1]=         0.0)
Epoch 17......Step: 2000/3166....... Loss=  2.3593e+07 (l[xt<-xt1]=  2.3593e+07,l[x0<-x1]=         0.0)
Epoch 17......Step: 2500/3166....... Loss=   2.949e+07 (l[xt<-xt1]=   2.949e+07,l[x0<-x1]=         0.0)
Epoch 17......Step: 3000/3166....... Loss=  3.5388e+07 (l[xt<-xt1]=  3.5388e+07,l[x0<-x1]=         0.0)
202599
Epoch 17/500 Done, Loss =   1.1796e+04 (l[xt<-xt1]=  1.1796e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16778        seconds
-----------------------------------------------------------
Epoch 18......Step: 500/3166....... Loss=  5.8969e+06 (l[xt<-xt1]=  5.8969e+06,l[x0<-x1]=         0.0)
Epoch 18......Step: 1000/3166....... Loss=  1.1793e+07 (l[xt<-xt1]=  1.1793e+07,l[x0<-x1]=         0.0)
Epoch 18......Step: 1500/3166....... Loss=  1.7689e+07 (l[xt<-xt1]=  1.7689e+07,l[x0<-x1]=         0.0)
Epoch 18......Step: 2000/3166....... Loss=  2.3585e+07 (l[xt<-xt1]=  2.3585e+07,l[x0<-x1]=         0.0)
Epoch 18......Step: 2500/3166....... Loss=  2.9479e+07 (l[xt<-xt1]=  2.9479e+07,l[x0<-x1]=         0.0)
Epoch 18......Step: 3000/3166....... Loss=  3.5374e+07 (l[xt<-xt1]=  3.5374e+07,l[x0<-x1]=         0.0)
202599
Epoch 18/500 Done, Loss =   1.1791e+04 (l[xt<-xt1]=  1.1791e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=17576        seconds
-----------------------------------------------------------
Epoch 19......Step: 500/3166....... Loss=  5.8939e+06 (l[xt<-xt1]=  5.8939e+06,l[x0<-x1]=         0.0)
Epoch 19......Step: 1000/3166....... Loss=  1.1788e+07 (l[xt<-xt1]=  1.1788e+07,l[x0<-x1]=         0.0)
Epoch 19......Step: 1500/3166....... Loss=  1.7682e+07 (l[xt<-xt1]=  1.7682e+07,l[x0<-x1]=         0.0)
Epoch 19......Step: 2000/3166....... Loss=  2.3576e+07 (l[xt<-xt1]=  2.3576e+07,l[x0<-x1]=         0.0)
Epoch 19......Step: 2500/3166....... Loss=  2.9469e+07 (l[xt<-xt1]=  2.9469e+07,l[x0<-x1]=         0.0)
Epoch 19......Step: 3000/3166....... Loss=  3.5361e+07 (l[xt<-xt1]=  3.5361e+07,l[x0<-x1]=         0.0)
202599
Epoch 19/500 Done, Loss =   1.1787e+04 (l[xt<-xt1]=  1.1787e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=17560        seconds
-----------------------------------------------------------
Epoch 20......Step: 500/3166....... Loss=  5.8931e+06 (l[xt<-xt1]=  5.8931e+06,l[x0<-x1]=         0.0)
Epoch 20......Step: 1000/3166....... Loss=  1.1785e+07 (l[xt<-xt1]=  1.1785e+07,l[x0<-x1]=         0.0)
Epoch 20......Step: 1500/3166....... Loss=  1.7677e+07 (l[xt<-xt1]=  1.7677e+07,l[x0<-x1]=         0.0)
Epoch 20......Step: 2000/3166....... Loss=  2.3568e+07 (l[xt<-xt1]=  2.3568e+07,l[x0<-x1]=         0.0)
Epoch 20......Step: 2500/3166....... Loss=  2.9459e+07 (l[xt<-xt1]=  2.9459e+07,l[x0<-x1]=         0.0)
Epoch 20......Step: 3000/3166....... Loss=   3.535e+07 (l[xt<-xt1]=   3.535e+07,l[x0<-x1]=         0.0)
202599
Epoch 20/500 Done, Loss =   1.1783e+04 (l[xt<-xt1]=  1.1783e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=15188        seconds
-----------------------------------------------------------
Epoch 21......Step: 500/3166....... Loss=  5.8906e+06 (l[xt<-xt1]=  5.8906e+06,l[x0<-x1]=         0.0)
Epoch 21......Step: 1000/3166....... Loss=   1.178e+07 (l[xt<-xt1]=   1.178e+07,l[x0<-x1]=         0.0)
Epoch 21......Step: 1500/3166....... Loss=   1.767e+07 (l[xt<-xt1]=   1.767e+07,l[x0<-x1]=         0.0)
Epoch 21......Step: 2000/3166....... Loss=  2.3559e+07 (l[xt<-xt1]=  2.3559e+07,l[x0<-x1]=         0.0)
Epoch 21......Step: 2500/3166....... Loss=  2.9448e+07 (l[xt<-xt1]=  2.9448e+07,l[x0<-x1]=         0.0)
Epoch 21......Step: 3000/3166....... Loss=  3.5336e+07 (l[xt<-xt1]=  3.5336e+07,l[x0<-x1]=         0.0)
202599
Epoch 21/500 Done, Loss =   1.1779e+04 (l[xt<-xt1]=  1.1779e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=15310        seconds
-----------------------------------------------------------
Epoch 22......Step: 500/3166....... Loss=  5.8884e+06 (l[xt<-xt1]=  5.8884e+06,l[x0<-x1]=         0.0)
Epoch 22......Step: 1000/3166....... Loss=  1.1776e+07 (l[xt<-xt1]=  1.1776e+07,l[x0<-x1]=         0.0)
Epoch 22......Step: 1500/3166....... Loss=  1.7665e+07 (l[xt<-xt1]=  1.7665e+07,l[x0<-x1]=         0.0)
Epoch 22......Step: 2000/3166....... Loss=  2.3553e+07 (l[xt<-xt1]=  2.3553e+07,l[x0<-x1]=         0.0)
Epoch 22......Step: 2500/3166....... Loss=   2.944e+07 (l[xt<-xt1]=   2.944e+07,l[x0<-x1]=         0.0)
Epoch 22......Step: 3000/3166....... Loss=  3.5327e+07 (l[xt<-xt1]=  3.5327e+07,l[x0<-x1]=         0.0)
202599
Epoch 22/500 Done, Loss =   1.1776e+04 (l[xt<-xt1]=  1.1776e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=15383        seconds
-----------------------------------------------------------
Epoch 23......Step: 500/3166....... Loss=  5.8866e+06 (l[xt<-xt1]=  5.8866e+06,l[x0<-x1]=         0.0)
Epoch 23......Step: 1000/3166....... Loss=  1.1774e+07 (l[xt<-xt1]=  1.1774e+07,l[x0<-x1]=         0.0)
Epoch 23......Step: 1500/3166....... Loss=   1.766e+07 (l[xt<-xt1]=   1.766e+07,l[x0<-x1]=         0.0)
Epoch 23......Step: 2000/3166....... Loss=  2.3545e+07 (l[xt<-xt1]=  2.3545e+07,l[x0<-x1]=         0.0)
Epoch 23......Step: 2500/3166....... Loss=  2.9431e+07 (l[xt<-xt1]=  2.9431e+07,l[x0<-x1]=         0.0)
Epoch 23......Step: 3000/3166....... Loss=  3.5317e+07 (l[xt<-xt1]=  3.5317e+07,l[x0<-x1]=         0.0)
202599
Epoch 23/500 Done, Loss =   1.1772e+04 (l[xt<-xt1]=  1.1772e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16806        seconds
-----------------------------------------------------------
Epoch 24......Step: 500/3166....... Loss=  5.8856e+06 (l[xt<-xt1]=  5.8856e+06,l[x0<-x1]=         0.0)
Epoch 24......Step: 1000/3166....... Loss=   1.177e+07 (l[xt<-xt1]=   1.177e+07,l[x0<-x1]=         0.0)
Epoch 24......Step: 1500/3166....... Loss=  1.7655e+07 (l[xt<-xt1]=  1.7655e+07,l[x0<-x1]=         0.0)
Epoch 24......Step: 2000/3166....... Loss=  2.3539e+07 (l[xt<-xt1]=  2.3539e+07,l[x0<-x1]=         0.0)
Epoch 24......Step: 2500/3166....... Loss=  2.9424e+07 (l[xt<-xt1]=  2.9424e+07,l[x0<-x1]=         0.0)
Epoch 24......Step: 3000/3166....... Loss=  3.5308e+07 (l[xt<-xt1]=  3.5308e+07,l[x0<-x1]=         0.0)
202599
Epoch 24/500 Done, Loss =   1.1769e+04 (l[xt<-xt1]=  1.1769e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16941        seconds
-----------------------------------------------------------
Epoch 25......Step: 500/3166....... Loss=  5.8838e+06 (l[xt<-xt1]=  5.8838e+06,l[x0<-x1]=         0.0)
Epoch 25......Step: 1000/3166....... Loss=  1.1767e+07 (l[xt<-xt1]=  1.1767e+07,l[x0<-x1]=         0.0)
Epoch 25......Step: 1500/3166....... Loss=  1.7651e+07 (l[xt<-xt1]=  1.7651e+07,l[x0<-x1]=         0.0)
Epoch 25......Step: 2000/3166....... Loss=  2.3534e+07 (l[xt<-xt1]=  2.3534e+07,l[x0<-x1]=         0.0)
Epoch 25......Step: 2500/3166....... Loss=  2.9416e+07 (l[xt<-xt1]=  2.9416e+07,l[x0<-x1]=         0.0)
Epoch 25......Step: 3000/3166....... Loss=    3.53e+07 (l[xt<-xt1]=    3.53e+07,l[x0<-x1]=         0.0)
202599
Epoch 25/500 Done, Loss =   1.1766e+04 (l[xt<-xt1]=  1.1766e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16793        seconds
-----------------------------------------------------------
Epoch 26......Step: 500/3166....... Loss=   5.882e+06 (l[xt<-xt1]=   5.882e+06,l[x0<-x1]=         0.0)
Epoch 26......Step: 1000/3166....... Loss=  1.1764e+07 (l[xt<-xt1]=  1.1764e+07,l[x0<-x1]=         0.0)
Epoch 26......Step: 1500/3166....... Loss=  1.7646e+07 (l[xt<-xt1]=  1.7646e+07,l[x0<-x1]=         0.0)
Epoch 26......Step: 2000/3166....... Loss=  2.3527e+07 (l[xt<-xt1]=  2.3527e+07,l[x0<-x1]=         0.0)
Epoch 26......Step: 2500/3166....... Loss=  2.9409e+07 (l[xt<-xt1]=  2.9409e+07,l[x0<-x1]=         0.0)
Epoch 26......Step: 3000/3166....... Loss=  3.5291e+07 (l[xt<-xt1]=  3.5291e+07,l[x0<-x1]=         0.0)
202599
Epoch 26/500 Done, Loss =   1.1764e+04 (l[xt<-xt1]=  1.1764e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16661        seconds
-----------------------------------------------------------
Epoch 27......Step: 500/3166....... Loss=  5.8807e+06 (l[xt<-xt1]=  5.8807e+06,l[x0<-x1]=         0.0)
Epoch 27......Step: 1000/3166....... Loss=  1.1762e+07 (l[xt<-xt1]=  1.1762e+07,l[x0<-x1]=         0.0)
Epoch 27......Step: 1500/3166....... Loss=  1.7643e+07 (l[xt<-xt1]=  1.7643e+07,l[x0<-x1]=         0.0)
Epoch 27......Step: 2000/3166....... Loss=  2.3523e+07 (l[xt<-xt1]=  2.3523e+07,l[x0<-x1]=         0.0)
Epoch 27......Step: 2500/3166....... Loss=  2.9403e+07 (l[xt<-xt1]=  2.9403e+07,l[x0<-x1]=         0.0)
Epoch 27......Step: 3000/3166....... Loss=  3.5283e+07 (l[xt<-xt1]=  3.5283e+07,l[x0<-x1]=         0.0)
202599
Epoch 27/500 Done, Loss =   1.1761e+04 (l[xt<-xt1]=  1.1761e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16567        seconds
-----------------------------------------------------------
Epoch 28......Step: 500/3166....... Loss=  5.8798e+06 (l[xt<-xt1]=  5.8798e+06,l[x0<-x1]=         0.0)
Epoch 28......Step: 1000/3166....... Loss=   1.176e+07 (l[xt<-xt1]=   1.176e+07,l[x0<-x1]=         0.0)
Epoch 28......Step: 1500/3166....... Loss=   1.764e+07 (l[xt<-xt1]=   1.764e+07,l[x0<-x1]=         0.0)
Epoch 28......Step: 2000/3166....... Loss=   2.352e+07 (l[xt<-xt1]=   2.352e+07,l[x0<-x1]=         0.0)
Epoch 28......Step: 2500/3166....... Loss=  2.9399e+07 (l[xt<-xt1]=  2.9399e+07,l[x0<-x1]=         0.0)
Epoch 28......Step: 3000/3166....... Loss=  3.5277e+07 (l[xt<-xt1]=  3.5277e+07,l[x0<-x1]=         0.0)
202599
Epoch 28/500 Done, Loss =   1.1759e+04 (l[xt<-xt1]=  1.1759e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16289        seconds
-----------------------------------------------------------
Epoch 29......Step: 500/3166....... Loss=  5.8786e+06 (l[xt<-xt1]=  5.8786e+06,l[x0<-x1]=         0.0)
Epoch 29......Step: 1000/3166....... Loss=  1.1758e+07 (l[xt<-xt1]=  1.1758e+07,l[x0<-x1]=         0.0)
Epoch 29......Step: 1500/3166....... Loss=  1.7636e+07 (l[xt<-xt1]=  1.7636e+07,l[x0<-x1]=         0.0)
Epoch 29......Step: 2000/3166....... Loss=  2.3514e+07 (l[xt<-xt1]=  2.3514e+07,l[x0<-x1]=         0.0)
Epoch 29......Step: 2500/3166....... Loss=  2.9392e+07 (l[xt<-xt1]=  2.9392e+07,l[x0<-x1]=         0.0)
Epoch 29......Step: 3000/3166....... Loss=   3.527e+07 (l[xt<-xt1]=   3.527e+07,l[x0<-x1]=         0.0)
202599
Epoch 29/500 Done, Loss =   1.1757e+04 (l[xt<-xt1]=  1.1757e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=17829        seconds
-----------------------------------------------------------
Epoch 30......Step: 500/3166....... Loss=  5.8773e+06 (l[xt<-xt1]=  5.8773e+06,l[x0<-x1]=         0.0)
Epoch 30......Step: 1000/3166....... Loss=  1.1754e+07 (l[xt<-xt1]=  1.1754e+07,l[x0<-x1]=         0.0)
Epoch 30......Step: 1500/3166....... Loss=  1.7632e+07 (l[xt<-xt1]=  1.7632e+07,l[x0<-x1]=         0.0)
Epoch 30......Step: 2000/3166....... Loss=  2.3509e+07 (l[xt<-xt1]=  2.3509e+07,l[x0<-x1]=         0.0)
Epoch 30......Step: 2500/3166....... Loss=  2.9386e+07 (l[xt<-xt1]=  2.9386e+07,l[x0<-x1]=         0.0)
Epoch 30......Step: 3000/3166....... Loss=  3.5263e+07 (l[xt<-xt1]=  3.5263e+07,l[x0<-x1]=         0.0)
202599
Epoch 30/500 Done, Loss =   1.1754e+04 (l[xt<-xt1]=  1.1754e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=17646        seconds
-----------------------------------------------------------
Epoch 31......Step: 500/3166....... Loss=  5.8767e+06 (l[xt<-xt1]=  5.8767e+06,l[x0<-x1]=         0.0)
Epoch 31......Step: 1000/3166....... Loss=  1.1753e+07 (l[xt<-xt1]=  1.1753e+07,l[x0<-x1]=         0.0)
Epoch 31......Step: 1500/3166....... Loss=   1.763e+07 (l[xt<-xt1]=   1.763e+07,l[x0<-x1]=         0.0)
Epoch 31......Step: 2000/3166....... Loss=  2.3506e+07 (l[xt<-xt1]=  2.3506e+07,l[x0<-x1]=         0.0)
Epoch 31......Step: 2500/3166....... Loss=  2.9383e+07 (l[xt<-xt1]=  2.9383e+07,l[x0<-x1]=         0.0)
Epoch 31......Step: 3000/3166....... Loss=  3.5259e+07 (l[xt<-xt1]=  3.5259e+07,l[x0<-x1]=         0.0)
202599
Epoch 31/500 Done, Loss =   1.1753e+04 (l[xt<-xt1]=  1.1753e+04,l[x0<-x1]=         0.0)
Total Time Elapsed=16727        seconds
-----------------------------------------------------------
Epoch 32......Step: 500/3166....... Loss=  5.8765e+06 (l[xt<-xt1]=  5.8765e+06,l[x0<-x1]=         0.0)
Epoch 32......Step: 1000/3166....... Loss=  1.1753e+07 (l[xt<-xt1]=  1.1753e+07,l[x0<-x1]=         0.0)
Epoch 32......Step: 1500/3166....... Loss=  1.7629e+07 (l[xt<-xt1]=  1.7629e+07,l[x0<-x1]=         0.0)
Epoch 32......Step: 2000/3166....... Loss=  2.3505e+07 (l[xt<-xt1]=  2.3505e+07,l[x0<-x1]=         0.0)
Epoch 32......Step: 2500/3166....... Loss=   2.938e+07 (l[xt<-xt1]=   2.938e+07,l[x0<-x1]=         0.0)
cuda:1
-----------------------------------------------------------
-----------------------------------------------------------
ENCODER
-----------------------------------------------------------
ModuleList(
  (0): convBlock(
    (net): ModuleList(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.1, inplace=False)
      (2): GroupNorm(4, 64, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.1, inplace=False)
      (6): GroupNorm(4, 64, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
  (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (2): convBlock(
    (net): ModuleList(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.1, inplace=False)
      (2): GroupNorm(4, 128, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.1, inplace=False)
      (6): GroupNorm(4, 128, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
  (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (4): convBlock(
    (net): ModuleList(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.1, inplace=False)
      (2): GroupNorm(4, 256, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.1, inplace=False)
      (6): GroupNorm(4, 256, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
)
-----------------------------------------------------------
-----------------------------------------------------------
DECODER
-----------------------------------------------------------
ModuleList(
  (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
  (1): convBlock(
    (net): ModuleList(
      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.1, inplace=False)
      (2): GroupNorm(4, 128, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.1, inplace=False)
      (6): GroupNorm(4, 128, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
  (2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
  (3): convBlock(
    (net): ModuleList(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.1, inplace=False)
      (2): GroupNorm(4, 64, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.1, inplace=False)
      (6): GroupNorm(4, 64, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
)
-----------------------------------------------------------
ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(3, 3), padding=(4, 4))
-----------------------------------------------------------
Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))
-----------------------------------------------------------
Tanh()
-----------------------------------------------------------
cuda:1
-----------------------------------------------------------
-----------------------------------------------------------
ENCODER
-----------------------------------------------------------
ModuleList(
  (0): convBlock(
    (net): ModuleList(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.1, inplace=False)
      (2): GroupNorm(4, 64, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.1, inplace=False)
      (6): GroupNorm(4, 64, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
  (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (2): convBlock(
    (net): ModuleList(
      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.1, inplace=False)
      (2): GroupNorm(4, 128, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.1, inplace=False)
      (6): GroupNorm(4, 128, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
  (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (4): convBlock(
    (net): ModuleList(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.1, inplace=False)
      (2): GroupNorm(4, 256, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.1, inplace=False)
      (6): GroupNorm(4, 256, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
)
-----------------------------------------------------------
-----------------------------------------------------------
DECODER
-----------------------------------------------------------
ModuleList(
  (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
  (1): convBlock(
    (net): ModuleList(
      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.1, inplace=False)
      (2): GroupNorm(4, 128, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.1, inplace=False)
      (6): GroupNorm(4, 128, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
  (2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
  (3): convBlock(
    (net): ModuleList(
      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
      (1): Dropout(p=0.1, inplace=False)
      (2): GroupNorm(4, 64, eps=1e-05, affine=True)
      (3): ReLU()
      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
      (5): Dropout(p=0.1, inplace=False)
      (6): GroupNorm(4, 64, eps=1e-05, affine=True)
      (7): ReLU()
    )
  )
)
-----------------------------------------------------------
ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(3, 3), padding=(4, 4))
-----------------------------------------------------------
Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))
-----------------------------------------------------------
Tanh()
-----------------------------------------------------------
